
[llm]
api_type= 'azure'
model = "gpt-4o-mini"
base_url = "https://ts-dev-001.openai.azure.com/openai/deployments/spotiq-gpt-4o"
api_key = "bd8f92b6bcde4156b35ffd63838df2b4"
# max_tokens = 8096
temperature = 0.3
api_version="2024-12-01-preview"

# Optional configuration for specific LLM models
[llm.vision]
model = "claude-3-5-sonnet"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."

# Azure Code Interpreter configuration
[azure_code_interpreter]
pool_endpoint = "https://<REGION>.dynamicsessions.io/subscriptions/<SUBSCRIPTION_ID>/resourceGroups/<RESOURCE_GROUP>/sessionPools/<SESSION_POOL_NAME>"
# If using an environment variable for the token, specify it here
token_env_var = "AZURE_CODE_INTERPRETER_TOKEN"
